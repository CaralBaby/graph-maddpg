Using good policy maddpg and adv policy maddpg
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -2223.2443974785524, agent episode reward: [-444.6488794957105, -444.6488794957105, -444.6488794957105, -444.6488794957105, -444.6488794957105], time: 100.494
steps: 49975, episodes: 2000, mean episode reward: -2469.307765944226, agent episode reward: [-493.8615531888452, -493.8615531888452, -493.8615531888452, -493.8615531888452, -493.8615531888452], time: 367.733
steps: 74975, episodes: 3000, mean episode reward: -2126.388764902186, agent episode reward: [-425.2777529804372, -425.2777529804372, -425.2777529804372, -425.2777529804372, -425.2777529804372], time: 382.934
steps: 99975, episodes: 4000, mean episode reward: -2102.571477909571, agent episode reward: [-420.51429558191427, -420.51429558191427, -420.51429558191427, -420.51429558191427, -420.51429558191427], time: 374.811
steps: 124975, episodes: 5000, mean episode reward: -1961.2468151866724, agent episode reward: [-392.24936303733455, -392.24936303733455, -392.24936303733455, -392.24936303733455, -392.24936303733455], time: 372.603
steps: 149975, episodes: 6000, mean episode reward: -1961.6181629410182, agent episode reward: [-392.32363258820357, -392.32363258820357, -392.32363258820357, -392.32363258820357, -392.32363258820357], time: 375.569
steps: 174975, episodes: 7000, mean episode reward: -1962.6502795102112, agent episode reward: [-392.53005590204225, -392.53005590204225, -392.53005590204225, -392.53005590204225, -392.53005590204225], time: 372.644
steps: 199975, episodes: 8000, mean episode reward: -1980.3176737046665, agent episode reward: [-396.0635347409333, -396.0635347409333, -396.0635347409333, -396.0635347409333, -396.0635347409333], time: 376.255
steps: 224975, episodes: 9000, mean episode reward: -1971.7135787890645, agent episode reward: [-394.3427157578129, -394.3427157578129, -394.3427157578129, -394.3427157578129, -394.3427157578129], time: 367.208
steps: 249975, episodes: 10000, mean episode reward: -1978.1098042402625, agent episode reward: [-395.62196084805254, -395.62196084805254, -395.62196084805254, -395.62196084805254, -395.62196084805254], time: 366.361
steps: 274975, episodes: 11000, mean episode reward: -1947.281862317345, agent episode reward: [-389.45637246346905, -389.45637246346905, -389.45637246346905, -389.45637246346905, -389.45637246346905], time: 373.781
steps: 299975, episodes: 12000, mean episode reward: -1954.7419024685223, agent episode reward: [-390.94838049370446, -390.94838049370446, -390.94838049370446, -390.94838049370446, -390.94838049370446], time: 397.03
steps: 324975, episodes: 13000, mean episode reward: -1939.8556291309726, agent episode reward: [-387.9711258261945, -387.9711258261945, -387.9711258261945, -387.9711258261945, -387.9711258261945], time: 396.588
steps: 349975, episodes: 14000, mean episode reward: -1958.3254444366491, agent episode reward: [-391.6650888873298, -391.6650888873298, -391.6650888873298, -391.6650888873298, -391.6650888873298], time: 385.803
steps: 374975, episodes: 15000, mean episode reward: -1945.5287671363592, agent episode reward: [-389.10575342727185, -389.10575342727185, -389.10575342727185, -389.10575342727185, -389.10575342727185], time: 375.834
steps: 399975, episodes: 16000, mean episode reward: -1951.52753747261, agent episode reward: [-390.3055074945219, -390.3055074945219, -390.3055074945219, -390.3055074945219, -390.3055074945219], time: 394.569
steps: 424975, episodes: 17000, mean episode reward: -1922.78815577775, agent episode reward: [-384.55763115555004, -384.55763115555004, -384.55763115555004, -384.55763115555004, -384.55763115555004], time: 389.587
steps: 449975, episodes: 18000, mean episode reward: -1938.1458702159796, agent episode reward: [-387.6291740431959, -387.6291740431959, -387.6291740431959, -387.6291740431959, -387.6291740431959], time: 412.855
steps: 474975, episodes: 19000, mean episode reward: -1942.3520763062816, agent episode reward: [-388.4704152612563, -388.4704152612563, -388.4704152612563, -388.4704152612563, -388.4704152612563], time: 387.85
steps: 499975, episodes: 20000, mean episode reward: -1912.255085563967, agent episode reward: [-382.4510171127934, -382.4510171127934, -382.4510171127934, -382.4510171127934, -382.4510171127934], time: 419.239
steps: 524975, episodes: 21000, mean episode reward: -1897.2939045290282, agent episode reward: [-379.4587809058056, -379.4587809058056, -379.4587809058056, -379.4587809058056, -379.4587809058056], time: 424.898
steps: 24975, episodes: 1000, mean episode reward: -1960.7507797054964, agent episode reward: [-392.1501559410993, -392.1501559410993, -392.1501559410993, -392.1501559410993, -392.1501559410993], time: 74.329
steps: 49975, episodes: 2000, mean episode reward: -1951.4837019625709, agent episode reward: [-390.2967403925142, -390.2967403925142, -390.2967403925142, -390.2967403925142, -390.2967403925142], time: 303.227
steps: 74975, episodes: 3000, mean episode reward: -1953.4388233840439, agent episode reward: [-390.68776467680874, -390.68776467680874, -390.68776467680874, -390.68776467680874, -390.68776467680874], time: 300.972
steps: 99975, episodes: 4000, mean episode reward: -1940.2338208163667, agent episode reward: [-388.04676416327334, -388.04676416327334, -388.04676416327334, -388.04676416327334, -388.04676416327334], time: 315.562
steps: 124975, episodes: 5000, mean episode reward: -1943.6113413667101, agent episode reward: [-388.72226827334197, -388.72226827334197, -388.72226827334197, -388.72226827334197, -388.72226827334197], time: 301.126
steps: 149975, episodes: 6000, mean episode reward: -1942.8908193283917, agent episode reward: [-388.57816386567833, -388.57816386567833, -388.57816386567833, -388.57816386567833, -388.57816386567833], time: 305.104
steps: 174975, episodes: 7000, mean episode reward: -1927.1400244493584, agent episode reward: [-385.4280048898717, -385.4280048898717, -385.4280048898717, -385.4280048898717, -385.4280048898717], time: 307.742
steps: 199975, episodes: 8000, mean episode reward: -1925.1696605543257, agent episode reward: [-385.0339321108651, -385.0339321108651, -385.0339321108651, -385.0339321108651, -385.0339321108651], time: 306.332
steps: 224975, episodes: 9000, mean episode reward: -1941.441589908708, agent episode reward: [-388.2883179817416, -388.2883179817416, -388.2883179817416, -388.2883179817416, -388.2883179817416], time: 306.659
steps: 249975, episodes: 10000, mean episode reward: -1937.1181312435688, agent episode reward: [-387.4236262487138, -387.4236262487138, -387.4236262487138, -387.4236262487138, -387.4236262487138], time: 323.675
steps: 274975, episodes: 11000, mean episode reward: -1911.0778790951497, agent episode reward: [-382.2155758190299, -382.2155758190299, -382.2155758190299, -382.2155758190299, -382.2155758190299], time: 352.606
steps: 299975, episodes: 12000, mean episode reward: -1905.8421971071045, agent episode reward: [-381.16843942142094, -381.16843942142094, -381.16843942142094, -381.16843942142094, -381.16843942142094], time: 362.779
steps: 324975, episodes: 13000, mean episode reward: -1920.2456225673363, agent episode reward: [-384.04912451346723, -384.04912451346723, -384.04912451346723, -384.04912451346723, -384.04912451346723], time: 362.834
steps: 349975, episodes: 14000, mean episode reward: -1918.8632888495326, agent episode reward: [-383.7726577699066, -383.7726577699066, -383.7726577699066, -383.7726577699066, -383.7726577699066], time: 365.576
steps: 374975, episodes: 15000, mean episode reward: -1914.6319174413907, agent episode reward: [-382.92638348827813, -382.92638348827813, -382.92638348827813, -382.92638348827813, -382.92638348827813], time: 369.685
steps: 399975, episodes: 16000, mean episode reward: -1888.9557271032663, agent episode reward: [-377.79114542065327, -377.79114542065327, -377.79114542065327, -377.79114542065327, -377.79114542065327], time: 374.522
steps: 424975, episodes: 17000, mean episode reward: -1924.1579872543034, agent episode reward: [-384.83159745086067, -384.83159745086067, -384.83159745086067, -384.83159745086067, -384.83159745086067], time: 372.544
steps: 449975, episodes: 18000, mean episode reward: -1901.8120829552495, agent episode reward: [-380.3624165910499, -380.3624165910499, -380.3624165910499, -380.3624165910499, -380.3624165910499], time: 385.349
steps: 474975, episodes: 19000, mean episode reward: -1907.8933247582297, agent episode reward: [-381.578664951646, -381.578664951646, -381.578664951646, -381.578664951646, -381.578664951646], time: 386.847
steps: 499975, episodes: 20000, mean episode reward: -1902.460524233149, agent episode reward: [-380.4921048466298, -380.4921048466298, -380.4921048466298, -380.4921048466298, -380.4921048466298], time: 387.26
steps: 524975, episodes: 21000, mean episode reward: -1911.7977726110705, agent episode reward: [-382.3595545222141, -382.3595545222141, -382.3595545222141, -382.3595545222141, -382.3595545222141], time: 390.334
steps: 549975, episodes: 22000, mean episode reward: -1896.3153395105858, agent episode reward: [-379.26306790211714, -379.26306790211714, -379.26306790211714, -379.26306790211714, -379.26306790211714], time: 402.452
steps: 574975, episodes: 23000, mean episode reward: -1906.3166418640856, agent episode reward: [-381.2633283728171, -381.2633283728171, -381.2633283728171, -381.2633283728171, -381.2633283728171], time: 399.302
